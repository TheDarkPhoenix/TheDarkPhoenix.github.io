<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2019-03-28T20:24:16+01:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Maciej Stępień</title><subtitle>Projekty</subtitle><entry><title type="html">Czołg</title><link href="http://localhost:4000/roboty/2019/03/27/tank/" rel="alternate" type="text/html" title="Czołg" /><published>2019-03-27T00:00:00+01:00</published><updated>2019-03-27T00:00:00+01:00</updated><id>http://localhost:4000/roboty/2019/03/27/tank</id><content type="html" xml:base="http://localhost:4000/roboty/2019/03/27/tank/">&lt;p&gt;Pojazd uniwersalny oparty o Raspberry Pi Zero.&lt;/p&gt;

&lt;figure class=&quot;figure  figure--center&quot;&gt;
  &lt;img class=&quot;image&quot; src=&quot;/pics/Czolg/front.jpg&quot; alt=&quot;&quot; width=&quot;600&quot; height=&quot;800&quot; /&gt;
  
&lt;/figure&gt;

&lt;p&gt;Umożliwia obserwację obrazu z kamerki, odczyt napięcia na baterii (poziom rozładowania ), temperatury z Raspberry oraz wartości enkoderów. Dotychczas odczytów z enkoderów nie wykorzystałem w sposób praktyczny, jednak zamieszczenie ich umożliwi dalszy rozwój konstrukcji.&lt;/p&gt;

&lt;div class=&quot;embed-container&quot;&gt;
  &lt;iframe width=&quot;720&quot; height=&quot;405&quot; src=&quot;https://drive.google.com/file/d/1QSsrb819J34oQ7zTbSGpt-7YVE9Y9KgX/preview&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;
  &lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;Projekt ten zaczął się od płytki PCB.&lt;/p&gt;
&lt;figure class=&quot;figure  figure--center&quot;&gt;
  &lt;img class=&quot;image&quot; src=&quot;/pics/Czolg/pierwotna.jpg&quot; alt=&quot;Płytka wraz z podłączonymi wszystkimi elementami&quot; width=&quot;600&quot; height=&quot;800&quot; /&gt;
  &lt;figcaption class=&quot;caption&quot;&gt;Płytka wraz z podłączonymi wszystkimi elementami&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Miała być wykorzystana do sterowania robotem z następującymi elementami:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;dwa silniki z enkoderami&lt;/li&gt;
  &lt;li&gt;trzy serwa&lt;/li&gt;
  &lt;li&gt;komunikacja z Raspberry pooprzez SPI&lt;/li&gt;
  &lt;li&gt;pomiar napięcia z baterii&lt;/li&gt;
  &lt;li&gt;dwa LEDy ( uruchomienie oraz rozładowanie)&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;figure  figure--center&quot;&gt;
  &lt;img class=&quot;image&quot; src=&quot;/pics/Czolg/testowanie.jpg&quot; alt=&quot;Złożony schemat prototypowany na płytce stykowej&quot; width=&quot;600&quot; height=&quot;800&quot; /&gt;
  &lt;figcaption class=&quot;caption&quot;&gt;Złożony schemat prototypowany na płytce stykowej&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Jako źródło zasilania wykorzystałem LiPola oraz 2 przetwornicę: jedną do logigki oraz drugą do serw. W trakcie realizacji projektu jednak zorientowałem się, że ten mikrokontroler jest za słaby. Było to spowodowane tym, że potrzebowałem 3 kanałów PWM do serw oraz 2 do sterowania prędkością silników. Nie miałem jednak dostępnej takiej liczby, dlatego sygnały PWM dla serw musiałem generować programowo, przez co znacznie wzrosło obciążenie procesora. Doliczając do tego bardzo często przerwania zewnętrzne z dwóch enkoderów, nie byłem w stanie dostarczyć wystarczająco dokładnego przebiegu PWM by sterować serwami. Dlatego ostatecznie pominąłem użycie serw w tym projekcie.&lt;/p&gt;

&lt;figure class=&quot;figure  figure--center&quot;&gt;
  &lt;img class=&quot;image&quot; src=&quot;/pics/Czolg/plytkawobudowie.jpg&quot; alt=&quot;&quot; width=&quot;600&quot; height=&quot;800&quot; /&gt;
  
&lt;/figure&gt;

&lt;p&gt;Konstrukcja czołgu została wykonana na drukarce 3D, a jej projekt zaczerpnąłem z 
&lt;a href=&quot;https://www.thingiverse.com/thing:652851&quot; title=&quot;Konstrukcja&quot;&gt;https://www.thingiverse.com/thing:652851&lt;/a&gt;&lt;/p&gt;

&lt;figure class=&quot;figure  figure--center&quot;&gt;
  &lt;img class=&quot;image&quot; src=&quot;/pics/Czolg/plytka.jpg&quot; alt=&quot;Płytka po wytrawieniu&quot; width=&quot;600&quot; height=&quot;800&quot; /&gt;
  &lt;figcaption class=&quot;caption&quot;&gt;Płytka po wytrawieniu&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Robotem steruje się poprzez przeglądarkę. W tym celu użyłem skryptu z &lt;a href=&quot;https://hackaday.io/project/25092-zerobot-raspberry-pi-zero-fpv-robot/log/97988-the-new-zerobot-pro&quot; title=&quot;Skrypt&quot;&gt;https://hackaday.io/project/25092-zerobot-raspberry-pi-zero-fpv-robot/log/97988-the-new-zerobot-pro&lt;/a&gt;
,który odpowiednio przerobiłem do swoich potrzeb ( zamiana sterowania na takie wykorzystujące SPI).&lt;/p&gt;

&lt;p&gt;&lt;a class=&quot;button&quot; href=&quot;https://github.com/TheDarkPhoenix/Tank&quot; style=&quot;background: #0366d6&quot;&gt;Projekt  &lt;svg width=&quot;16&quot; height=&quot;16&quot; class=&quot;icon  icon--github&quot; role=&quot;img&quot; alt=&quot;github&quot;&gt;&lt;title&gt;github&lt;/title&gt;&lt;use xlink:href=&quot;#github&quot; fill=&quot;CurrentColor&quot;&gt;&lt;/use&gt;&lt;/svg&gt;
&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">Pojazd uniwersalny oparty o Raspberry Pi Zero.</summary></entry><entry><title type="html">Hexapod</title><link href="http://localhost:4000/roboty/2018/06/08/hexapod/" rel="alternate" type="text/html" title="Hexapod" /><published>2018-06-08T00:00:00+02:00</published><updated>2018-06-08T00:00:00+02:00</updated><id>http://localhost:4000/roboty/2018/06/08/hexapod</id><content type="html" xml:base="http://localhost:4000/roboty/2018/06/08/hexapod/">&lt;p&gt;Sześcionogi stwór z kamerkami.&lt;/p&gt;

&lt;p&gt;Projekt, którym zajmowałem się przez pierwsze 2 lata studiów w ramach działalności koła naukowego Integra. Moim wkładem było oprogramowanie do sterowania robota oraz stereowizji.&lt;/p&gt;

&lt;figure class=&quot;figure  figure--center&quot;&gt;
  &lt;img class=&quot;image&quot; src=&quot;/pics/Hexapod/hexi.jpg&quot; alt=&quot;&quot; width=&quot;600&quot; height=&quot;800&quot; /&gt;
  
&lt;/figure&gt;

&lt;p&gt;Do poruszania konstrukcją wykorzystane zostało 18 serw Hitec po 3 na każdą nogę. Jako główny komputer robota wykorzystalismy Raspberry Pi 2. Komunikowała się ona z sterownikiem serw Pololu poprzez interfejs UART umożliwiając zadawanie odpowiednich pozycji serw. Całą konstrukcję zasila bateria LiPol o pojemności 4000 mAh, co pozwalało na ok. 1h użytkowania robota. Napięcie z akumulatora  dostowywaliśmy za pomocą przetwornic (3 do zasilania serw oraz 1 dla Raspberry). Wykorzystaliśmy także przetwornik ADC MCP3008, aby móc mierzyć aktualne napięcie na baterii. Komunikował się on z Raspberry za pomocą SPI, a następnie napięcie było wysyłane i wyświetlane w aplikacji klienta.&lt;/p&gt;

&lt;div class=&quot;embed-container&quot;&gt;
  &lt;iframe width=&quot;720&quot; height=&quot;405&quot; src=&quot;https://drive.google.com/file/d/1kR9fSGo-6mLM5SdvNPUtoAvgJeeI8Lu-/preview&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;
  &lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;Robot jest sterowany z poziomu laptopa, który komunikuje się z Raspberry poprzez WiFi przez protokół TCP. Do poruszania robotem można używać zarówno pada jak i klawiatury. W celu odpowiedniego sterowania najpierw napisałem aplikację obrazującą model matematyczny robota. Na tym modelu została zaimplementowana kinematyka odwrotna, na której następnie stworzyłem modele poruszania się robota. Odpowiednio przeliczone uzyskane kąty na sygnały PWM dla serwonapędów były wysyłane do sterownika.&lt;/p&gt;

&lt;figure class=&quot;figure  figure--center&quot;&gt;
  &lt;img class=&quot;image&quot; src=&quot;/pics/Hexapod/symulacja.png&quot; alt=&quot;&quot; width=&quot;600&quot; height=&quot;800&quot; /&gt;
  
&lt;/figure&gt;

&lt;h2 id=&quot;sterowanie-robotem&quot;&gt;Sterowanie robotem&lt;/h2&gt;
&lt;p&gt;Aplikacja uruchamiana na laptopie zawiera wizualizacje modelu robota oraz odbiera sygnały sterowania od użytkownika, które następnie przekazuje do programu na Raspberry. On natomiast dokonuje odpowiednich przeliczeń na sygnały PWM, które następnie przekazuje do sterownika serw. Z Raspberry wysyłana jest także informacja zwrotna do aplikacji użytkownika z aktualnym napięciem na baterii, dzięki czemu jej poziom jest na bieżąco monitorowany. Osobny program służy do realizacji stereowizji. Raspberry wysyła obrazy z obu kamer przy użyciu programu gstreamer. Na laptopie oba obrazy są odbierane i następnie przy użyciu odpowiednich macierzy (uzyskanych podczas kalibracji) przekształcana oraz liczona jest macierz obrazu dysparcji. Zastosowałem także filtr po przeliczeniu dysparcji, który dodatkowo poprawia rezultaty.&lt;/p&gt;

&lt;p&gt;Aplikacje modelu Hexapoda można pracować w 2 trybach:&lt;/p&gt;

&lt;h4 id=&quot;tryb-modelu&quot;&gt;Tryb modelu&lt;/h4&gt;
&lt;p&gt;W trybie modelu można poruszać się po środowisku za pomocą klawiszy W/S/A/D/Q/E oraz barów alfa, beta i gamma służących do zmiany kąta widzenia. Modelem robota poruszać można za pomocą klawiszy w/s/a/d/q/e oraz numerów służących do wyboru odpowiedniego trybu chodzenia robota.&lt;/p&gt;

&lt;div class=&quot;embed-container&quot;&gt;
  &lt;iframe width=&quot;720&quot; height=&quot;405&quot; src=&quot;https://drive.google.com/file/d/1ixW05vog_nNaR9UR6ZqT5rZBkIWlBJeN/preview&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;
  &lt;/iframe&gt;
&lt;/div&gt;

&lt;h4 id=&quot;tryb-połączenia-z-hexapodem&quot;&gt;Tryb połączenia z Hexapodem&lt;/h4&gt;
&lt;p&gt;Uruchamia się jeśli dodatkowo przekażemy do programu przy uruchomieniu adres IP Raspberry. Sterowanie aplikacją na laptopie nie zmienia się. Różnica z poprzednio omówionym trybem (tryb modelu) jest taka, iż teraz odpowiednie komendy wysyłane są także do Hexapoda. Dodatkowo wyświetlane na ekranie laptopa jest również napięcie na baterii.&lt;/p&gt;

&lt;p&gt;Bliższy opis elementów zrealizowanej aplikacji&lt;/p&gt;
&lt;h4 id=&quot;gui&quot;&gt;GUI&lt;/h4&gt;
&lt;p&gt;Zadaniem najbardziej oddalonym od samej idei Hexapoda był moduł wyświetlania, czyli GUI. Do wyświetlania użyto wyłącznie prostego okienkowego trybu wyświetlania dołączonego do biblioteki OpenCV w celu debugowania. Zastosowałem rzutowanie perspektywiczne zgodnie ze wzorami zawartymi w &lt;a href=&quot;https://en.wikipedia.org/wiki/3D_projection&quot; title=&quot;1&quot;&gt;1&lt;/a&gt;, aby otrzymać symulację w 3D. Zdefiniowałem płaszczyznę kamery, na którą odbywało się rzutowanie świata 3D symulacji. Dodałęm także przesuwanie płaszczyzną kamery za pomocą przycisków oraz możliwość jej obracania przy pomocy toolbarów.&lt;/p&gt;
&lt;h4 id=&quot;robot&quot;&gt;Robot&lt;/h4&gt;
&lt;p&gt;To jest główny moduł odpowiedzialny za obliczenia związane ze sterowaniem robota. Zawarłem w nim implementację kinematyki odwrotnej w podejściu trygonometrycznym opisaną w &lt;a href=&quot;https://oscarliang.com/inverse-kinematics-and-trigonometry-basics/&quot; title=&quot;2&quot;&gt;2&lt;/a&gt;. Główna klasa robota zawiera klasę nóg robota, które są wydzielone. Jest osobna klasa, w której znajdują się różne algorytmy chodzenia.&lt;/p&gt;
&lt;h4 id=&quot;chodzenie&quot;&gt;Chodzenie&lt;/h4&gt;
&lt;p&gt;Najlepsze efekty dawało chodzenie po paraboli. Dobierane są kolejne punkty paraboli, która zaczyna się w miejscu, gdzie aktualnie znajduje się końcówka nogi robota. Kończy się tam, gdzie ma się ostatecznie znaleźć. Przy użyciu kinematyki odwrotnej wyliczane są kąty tak, aby końcówka danej nogi znalazła się w punkcie docelowym.&lt;/p&gt;
&lt;h4 id=&quot;pozostałe-moduły&quot;&gt;Pozostałe moduły&lt;/h4&gt;
&lt;p&gt;Kontroler, który odpowiednio interpretuje wysłane komendy na funkcje, np.: chodzenia lub poruszania bazą robota. Znajduje się tutaj również moduł do komunikacji z serwami (tylko w wersji programu dla Raspberry). Zamieniane są wyliczone kąty dla każdej nogi na odpowiednie sygnały PWM, dla każdego serwa (jedna noga składa się z trzech serwonapędów). Następnie są one wysyłane.&lt;/p&gt;
&lt;h4 id=&quot;tcp&quot;&gt;TCP&lt;/h4&gt;
&lt;p&gt;W module TCP znajduję się cały kod do komunikacji pomiędzy Raspberry a laptopem. Kod został zaczerpnięty z &lt;a href=&quot;https://github.com/vichargrave/tcpsockets&quot; title=&quot;3&quot;&gt;3&lt;/a&gt;. W ramach komunikacji laptop łączy się z Raspberry i na porcie 8081 odbiera aktualne napięcie baterii, które Raspberry stale udostępnia. Komunikacja w ramach odczytu napięcia baterii odbywa się w osobnym wątku, aby nie zakłócać pozostałych operacji. Natomiast na port 8080 aplikacja z laptopa wysyła podane komendy.&lt;/p&gt;

&lt;p&gt;&lt;a class=&quot;button&quot; href=&quot;https://github.com/TheDarkPhoenix/HexapodPC&quot; style=&quot;background: #0366d6&quot;&gt;Aplikacja na laptopa  &lt;svg width=&quot;16&quot; height=&quot;16&quot; class=&quot;icon  icon--github&quot; role=&quot;img&quot; alt=&quot;github&quot;&gt;&lt;title&gt;github&lt;/title&gt;&lt;use xlink:href=&quot;#github&quot; fill=&quot;CurrentColor&quot;&gt;&lt;/use&gt;&lt;/svg&gt;
&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a class=&quot;button&quot; href=&quot;https://github.com/TheDarkPhoenix/HexapodRaspberry&quot; style=&quot;background: #0366d6&quot;&gt;Aplikacja na Raspberry  &lt;svg width=&quot;16&quot; height=&quot;16&quot; class=&quot;icon  icon--github&quot; role=&quot;img&quot; alt=&quot;github&quot;&gt;&lt;title&gt;github&lt;/title&gt;&lt;use xlink:href=&quot;#github&quot; fill=&quot;CurrentColor&quot;&gt;&lt;/use&gt;&lt;/svg&gt;
&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;stereowizja&quot;&gt;Stereowizja&lt;/h2&gt;
&lt;p&gt;Poniżej przedstawie krótki opis etapów realizacji stereowizji:&lt;/p&gt;
&lt;h3 id=&quot;wykonanie-zdjęć-kalibracyjnych&quot;&gt;Wykonanie zdjęć kalibracyjnych&lt;/h3&gt;
&lt;p&gt;Aby skalibrować parę stereowizyjną wykonywane są zdjęcia ustalonego wzoru, np. szachownicy. W tym celu napisałem aplikację, która wyświetlała obraz z obu kamer. Co ustalony czas zapisywała zdjęcie pod odpowiednią nazwą oraz tworzyła listę utworzonych obrazów. Wykonałem około 50 zdjęć tak, aby jak najlepiej pokryć cały obszar widoku kamer.&lt;/p&gt;

&lt;figure class=&quot;figure  figure--center&quot;&gt;
  &lt;img class=&quot;image&quot; src=&quot;/pics/Hexapod/stereo12.png&quot; alt=&quot;Przykładowa para zdjęć wykonanych podczas kalibracji&quot; width=&quot;600&quot; height=&quot;800&quot; /&gt;
  &lt;figcaption class=&quot;caption&quot;&gt;Przykładowa para zdjęć wykonanych podczas kalibracji&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Widoczny na zdjęciach zamieszczonych powyżej jest także następny napotkany problem - obiektywy w obudowach kamer zamontowane były nierówno. Oczywiście to przesunięcie eliminowane jest podczas kalibracji, jednak w rezultacie podczas właściwej stereowizji ograniczone jest pole widzenia od góry i dołu (część pixeli widoczna jest tylko przez jedną kamerkę).&lt;/p&gt;
&lt;h3 id=&quot;kalibracja&quot;&gt;Kalibracja&lt;/h3&gt;
&lt;p&gt;Do samej kalibracji użyłem przykładu z książki Learning OpenCV. W parametrach wywołania umieszczano wysokość oraz szerokość szachownicy (liczba pól), a także długość boku kwadratu w centymetrach. Bardzo ważne jest, aby szachownica miała kwadratowe pola, gdyż przy użyciu szachownicy o bokach różniących się nieznacznie cały proces kalibracji zostałby przeprowadzony niepoprawnie wraz z listą zdjęć, powstałych w trakcie tej błędnej kalibracji.&lt;/p&gt;

&lt;figure class=&quot;figure  figure--center&quot;&gt;
  &lt;img class=&quot;image&quot; src=&quot;/pics/Hexapod/stereo3.png&quot; alt=&quot;Wynik wykrywania krawędzi szachownicy&quot; width=&quot;400&quot; height=&quot;800&quot; /&gt;
  &lt;figcaption class=&quot;caption&quot;&gt;Wynik wykrywania krawędzi szachownicy&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure class=&quot;figure  figure--center&quot;&gt;
  &lt;img class=&quot;image&quot; src=&quot;/pics/Hexapod/stereo4.png&quot; alt=&quot;Wynik rektyfikacji&quot; width=&quot;700&quot; height=&quot;800&quot; /&gt;
  &lt;figcaption class=&quot;caption&quot;&gt;Wynik rektyfikacji&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;W wyniku działania kalibracji otrzymałem parametry zewnętrzne oraz wewnętrzne kamer, które następnie używane były do właściwej stereowizji. Uzyskano błędy:
błąd średniokwadratowy (RMS) = 0.0503053
średni błąd epipolarny = 0.517146
Są to wartości niskie, co świadczy o poprawnie wykonanej kalibracji.&lt;/p&gt;
&lt;h3 id=&quot;wybór-algorytmu-oraz-dobranie-parametrów&quot;&gt;Wybór algorytmu oraz dobranie parametrów&lt;/h3&gt;
&lt;p&gt;Najpierw przetestowałem dostępne w bibliotece OpenCV algorytmy BM i SGBM, lepsze rezultaty uzyskałem dla SGBM. Jest on bardziej wymagający obliczeniowo, aczkolwiek przy rozdzielczości 320x240 można było uzyskać dobre przetwarzanie w czasie rzeczywistym. Następnie dobrałem optymalne parametry dla tego algorytmu. W tym celu napisałem aplikację na podstawie przykładu użycia SGBM zawartego w bibliotece OpenCV. Dodałem do niej suwak tak, aby można było wygodnie zmieniać parametry i obserwować uzyskiwane rezultatu.&lt;/p&gt;

&lt;figure class=&quot;figure  figure--center&quot;&gt;
  &lt;img class=&quot;image&quot; src=&quot;/pics/Hexapod/stereo5.png&quot; alt=&quot;Widok okna z paskami do zmiany parametrów&quot; width=&quot;400&quot; height=&quot;800&quot; /&gt;
  &lt;figcaption class=&quot;caption&quot;&gt;Widok okna z paskami do zmiany parametrów&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure class=&quot;figure  figure--center&quot;&gt;
  &lt;img class=&quot;image&quot; src=&quot;/pics/Hexapod/stereo6.png&quot; alt=&quot;Przykładowa scena użyta do doboru parametrów&quot; width=&quot;400&quot; height=&quot;800&quot; /&gt;
  &lt;figcaption class=&quot;caption&quot;&gt;Przykładowa scena użyta do doboru parametrów&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure class=&quot;figure  figure--center&quot;&gt;
  &lt;img class=&quot;image&quot; src=&quot;/pics/Hexapod/stereo7.png&quot; alt=&quot;Wynik przeprowadzenia stereowizji&quot; width=&quot;400&quot; height=&quot;800&quot; /&gt;
  &lt;figcaption class=&quot;caption&quot;&gt;Wynik przeprowadzenia stereowizji&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;dobranie-parametrów-dla-postfiltracji&quot;&gt;Dobranie parametrów dla postfiltracji&lt;/h3&gt;
&lt;p&gt;W celu uzyskania gładszego obrazu stereowizyjnego zastosowałem postfiltrację, która dodana została stosunkowo niedawno do modułów dodatkowych biblioteki OpenCV - contrib.&lt;/p&gt;

&lt;figure class=&quot;figure  figure--center&quot;&gt;
  &lt;img class=&quot;image&quot; src=&quot;/pics/Hexapod/stereo9.png&quot; alt=&quot;Efekt przeprowadzenia algorytmu SGBM przy optymalnych parametrach&quot; width=&quot;400&quot; height=&quot;800&quot; /&gt;
  &lt;figcaption class=&quot;caption&quot;&gt;Efekt przeprowadzenia algorytmu SGBM przy optymalnych parametrach&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure class=&quot;figure  figure--center&quot;&gt;
  &lt;img class=&quot;image&quot; src=&quot;/pics/Hexapod/stereo10.png&quot; alt=&quot;Efekt przeprowadzenia postfiltracji&quot; width=&quot;400&quot; height=&quot;800&quot; /&gt;
  &lt;figcaption class=&quot;caption&quot;&gt;Efekt przeprowadzenia postfiltracji&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;ostateczna-aplikacja&quot;&gt;Ostateczna aplikacja&lt;/h3&gt;
&lt;p&gt;W ostatecznej aplikacji połączone zostały wszystkie opisane elementy. W wyniku czego otrzymano przesył obrazu z obu kamer na laptopa. Tam obraz był rektyfikowany, a pixele były dopasowywane za pomocą algorytmu SGBM. Przy użyciu posfiltracji obraz dysparcji jest poprawiany i na koniec wyświetlany. Dalszym etapem rozwojowym może być przeliczenie chmury punktów na podstawie dysparcji oraz następnie wykrywanie i omijanie przeszkód.&lt;/p&gt;

&lt;p&gt;Poza samą realizacją stereowizji ważnym elementem był także optymalny przesył obrazu z obu kamer. Pierwszym podejściem było użycie MJPGstreamera. Efekty jednak nie były zadowalające. Klatki, które nie zostały jeszcze wysłane, były składowane w buforze. W wyniku czego, im dłużej działała aplikacja, tym większe było opóźnienie. Dodatkowo występowała różnica czasu pomiędzy klatkami z obu kamer, co w przypadku stereowizji jest nieakceptowalne. Dlatego zdecydowano się użyć gstreamera. Jest on bardziej zaawansowany, przez co uruchomienie go zajęło więcej czasu. Jednak uzyskany efekt jest bardzo dobry. W jego działaniu, jeśli nie zdąży się wysłać klatki przed przybyciem następnej, to zostaje ona porzucona. W wyniku tego wyeliminowane zostało rosnące opóźnienie. Dlatego też nie występowało już opóźnienie pomiędzy klatkami. Rozdzielczość przesyłanych obrazów wynosi 320x240. Przeprowadzono także testy dla rozdzielczości 640x480, ale spadek FPS był nieproporcjonalny do wzrostu jakości.&lt;/p&gt;

&lt;p&gt;&lt;a class=&quot;button&quot; href=&quot;https://github.com/TheDarkPhoenix/HexapodStereovision&quot; style=&quot;background: #0366d6&quot;&gt;Stereowizja  &lt;svg width=&quot;16&quot; height=&quot;16&quot; class=&quot;icon  icon--github&quot; role=&quot;img&quot; alt=&quot;github&quot;&gt;&lt;title&gt;github&lt;/title&gt;&lt;use xlink:href=&quot;#github&quot; fill=&quot;CurrentColor&quot;&gt;&lt;/use&gt;&lt;/svg&gt;
&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;osiągnięcia&quot;&gt;Osiągnięcia&lt;/h3&gt;
&lt;h4 id=&quot;zawody-robotyczne&quot;&gt;Zawody robotyczne&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Robocomp 2017 w Krakowie (kategoria Freestyle)&lt;/li&gt;
  &lt;li&gt;Robotic Arena 2017 we Wrocławiu (kategorie Freestyle oraz wyścig robotów kroczących). Pierwsze miejsce w kategorii wyścig robotów kroczących.&lt;/li&gt;
  &lt;li&gt;Robomaticon 2018 w Warszawie (kategoria Freestyle)&lt;/li&gt;
  &lt;li&gt;Robotic Tournament 2018 w Rybniku (kategoria Freestyle)&lt;/li&gt;
  &lt;li&gt;Robotic Arena 2019 we Wrocławiu. Drugie miejsce w kategorii wyścig robotów kroczących.
    &lt;h4 id=&quot;wydarzenia&quot;&gt;Wydarzenia&lt;/h4&gt;
  &lt;/li&gt;
  &lt;li&gt;Targi pracy Kariera IT&lt;/li&gt;
  &lt;li&gt;TEDxAGHUniversity&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;figure  figure--center&quot;&gt;
  &lt;img class=&quot;image&quot; src=&quot;/pics/Hexapod/robotic_arena.jpg&quot; alt=&quot;Prezentacja na zawodach Robotic Arena fot. Politechnika Wrocławska&quot; width=&quot;400&quot; height=&quot;800&quot; /&gt;
  &lt;figcaption class=&quot;caption&quot;&gt;Prezentacja na zawodach Robotic Arena fot. Politechnika Wrocławska&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;a href=&quot;http://www.integra.agh.edu.pl/robot-kroczacy-freestyle/&quot; title=&quot;Strona projektu&quot;&gt;Strona projektu&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">Sześcionogi stwór z kamerkami.</summary></entry><entry><title type="html">Świecąca kulka</title><link href="http://localhost:4000/oprogramowanie/2017/05/26/move/" rel="alternate" type="text/html" title="Świecąca kulka" /><published>2017-05-26T00:00:00+02:00</published><updated>2017-05-26T00:00:00+02:00</updated><id>http://localhost:4000/oprogramowanie/2017/05/26/move</id><content type="html" xml:base="http://localhost:4000/oprogramowanie/2017/05/26/move/">&lt;p&gt;Obsługa komputera poprzez ruchy kontrolerem.&lt;/p&gt;

&lt;figure class=&quot;figure  figure--center&quot;&gt;
  &lt;img class=&quot;image&quot; src=&quot;/pics/swiecacaKulka/kontroler.jpg&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;300&quot; /&gt;
  
&lt;/figure&gt;

&lt;p&gt;Kontroler zainspirowany rozwiązaniem z PlayStation. Użyłem kamerki internetowej oraz odpowiedniego kontrolera - latarki z kulką. Ruchy kulki są śledzone oraz przekładane na ruchy kursora myszy. Poprzez odpowiednie przygaszenie a następnie zaświecenie latarki symulowane jest kliknięcie.&lt;/p&gt;

&lt;p&gt;W celu analizy obrazu użyłem bibliotekę OpenCV oraz metodę wykrywania przedstawioną w &lt;a href=&quot;https://forbot.pl/blog/opencv-2-wykrywanie-obiektow-id4888&quot;&gt;https://forbot.pl/blog/opencv-2-wykrywanie-obiektow-id4888&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;embed-container&quot;&gt;
  &lt;iframe width=&quot;720&quot; height=&quot;405&quot; src=&quot;https://drive.google.com/file/d/1Ifl4nigfpzm73YRJDlyJJY3RQRywG9NQ/preview&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;
  &lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;&lt;a class=&quot;button&quot; href=&quot;https://github.com/TheDarkPhoenix/LightOrb&quot; style=&quot;background: #0366d6&quot;&gt;Kod  &lt;svg width=&quot;16&quot; height=&quot;16&quot; class=&quot;icon  icon--github&quot; role=&quot;img&quot; alt=&quot;github&quot;&gt;&lt;title&gt;github&lt;/title&gt;&lt;use xlink:href=&quot;#github&quot; fill=&quot;CurrentColor&quot;&gt;&lt;/use&gt;&lt;/svg&gt;
&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">Obsługa komputera poprzez ruchy kontrolerem.</summary></entry><entry><title type="html">Cewka Tesli</title><link href="http://localhost:4000/elektronika/2015/12/10/cewkatesli/" rel="alternate" type="text/html" title="Cewka Tesli" /><published>2015-12-10T00:00:00+01:00</published><updated>2015-12-10T00:00:00+01:00</updated><id>http://localhost:4000/elektronika/2015/12/10/cewkatesli</id><content type="html" xml:base="http://localhost:4000/elektronika/2015/12/10/cewkatesli/">&lt;p&gt;Robi się groźnie.&lt;/p&gt;

&lt;figure class=&quot;figure  figure--center&quot;&gt;
  &lt;img class=&quot;image&quot; src=&quot;/pics/cewkatesli/wieksza.jpg&quot; alt=&quot;&quot; width=&quot;600&quot; height=&quot;800&quot; /&gt;
  
&lt;/figure&gt;

&lt;p&gt;Projekt cewki tesli wykonany na podstawie 
&lt;a href=&quot;https://www.electroboom.com/?p=521&quot; title=&quot;ElectroBoom&quot;&gt;ElectroBoom&lt;/a&gt;
oraz
&lt;a href=&quot;https://www.youtube.com/watch?v=4OC7cwI4RNM&quot; title=&quot;Ludic Science&quot;&gt;Ludic Science&lt;/a&gt;&lt;/p&gt;

&lt;figure class=&quot;figure  figure--center&quot;&gt;
  &lt;img class=&quot;image&quot; src=&quot;/pics/cewkatesli/oryginal.jpg&quot; alt=&quot;&quot; width=&quot;400&quot; height=&quot;800&quot; /&gt;
  
&lt;/figure&gt;

&lt;p&gt;Najpierw wykonałem mniejszą wersję opartą na jednym tranzystorze, zasilaną baterią 9V.&lt;/p&gt;

&lt;figure class=&quot;figure  figure--center&quot;&gt;
  &lt;img class=&quot;image&quot; src=&quot;/pics/cewkatesli/nawijanie.jpg&quot; alt=&quot;Nawijanie cewki&quot; width=&quot;600&quot; height=&quot;800&quot; /&gt;
  &lt;figcaption class=&quot;caption&quot;&gt;Nawijanie cewki&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Następnie wykonałem cewkę o większych rozmiarach, w ktrórej zastosowałem 4 tranzystory oraz dodatkowy radiator, aby zapewnić odpowiednie chłodzenie. Jako źródło energii użyłem zasilacza od drukarki.&lt;/p&gt;</content><author><name></name></author><summary type="html">Robi się groźnie.</summary></entry><entry><title type="html">Robot mapujący</title><link href="http://localhost:4000/roboty/2015/08/25/mapping-robot/" rel="alternate" type="text/html" title="Robot mapujący" /><published>2015-08-25T00:00:00+02:00</published><updated>2015-08-25T00:00:00+02:00</updated><id>http://localhost:4000/roboty/2015/08/25/mapping-robot</id><content type="html" xml:base="http://localhost:4000/roboty/2015/08/25/mapping-robot/">&lt;p&gt;Robot laptopa wożący pokój mapujący.&lt;/p&gt;

&lt;figure class=&quot;figure  figure--center&quot;&gt;
  &lt;img class=&quot;image&quot; src=&quot;/pics/RobotMapujacy/front.jpg&quot; alt=&quot;&quot; width=&quot;600&quot; height=&quot;800&quot; /&gt;
  
&lt;/figure&gt;

&lt;p&gt;Ten robot jest drugą, uproszczoną wersją robota uniwersalnego. Wyciągając wnioski z poprzedniej konstrukcji uprościłem robota i jego jedynym zadaniem było mapowanie pomieszczeń. Także aby zadanie się udało zamieniłem Stereowizję na Kinecta, ponieważ rezultaty z niej osiągane nie były zadowalające. Dodałem także enkodery na koła, jednak wciąż zbyt pewny siebie zrobiłem swoje - inkrementalne bazujące na transoptorach. Nie sprawdzały się one idealnie, ale jednak pozwoliły osiągnąć rezultaty.&lt;/p&gt;

&lt;figure class=&quot;figure  figure--center&quot;&gt;
  &lt;img class=&quot;image&quot; src=&quot;/pics/RobotMapujacy/test.jpg&quot; alt=&quot;Prototypowanie eletkroniki&quot; width=&quot;600&quot; height=&quot;800&quot; /&gt;
  &lt;figcaption class=&quot;caption&quot;&gt;Prototypowanie eletkroniki&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Także w ramach zabawy z robotem zrealizowałem regulator PID i zadawałem punkt, do którego robot dojeżdżał.&lt;/p&gt;

&lt;p&gt;&lt;a class=&quot;button&quot; href=&quot;https://github.com/TheDarkPhoenix/MappingRobotPID&quot; style=&quot;background: #0366d6&quot;&gt;PID  &lt;svg width=&quot;16&quot; height=&quot;16&quot; class=&quot;icon  icon--github&quot; role=&quot;img&quot; alt=&quot;github&quot;&gt;&lt;title&gt;github&lt;/title&gt;&lt;use xlink:href=&quot;#github&quot; fill=&quot;CurrentColor&quot;&gt;&lt;/use&gt;&lt;/svg&gt;
&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;embed-container&quot;&gt;
  &lt;iframe width=&quot;720&quot; height=&quot;405&quot; src=&quot;https://drive.google.com/file/d/1SI5PMQt-zXZ0vf6xvoXPK_p1-t72E7ty/preview&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;
  &lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;Aby stworzyć mapę najpierw podrzebowałem odpowiednio obrobić dane. W danych głębi z Kinecta zawarte były informacje o podłodze oraz obiektach. Musiałem pozbyć się podłogi. Do osiągnięcia tego testowałem 2 metody: dopasowywanie płaszczyzny oparte na RANSACu z OpenCV oraz metodą UV-disparity, która przyspieszała obliczenia - wykrywałem linię zamiast płaszczyzny.&lt;/p&gt;

&lt;figure class=&quot;figure  figure--center&quot;&gt;
  &lt;img class=&quot;image&quot; src=&quot;/pics/RobotMapujacy/side.jpg&quot; alt=&quot;&quot; width=&quot;600&quot; height=&quot;800&quot; /&gt;
  
&lt;/figure&gt;

&lt;p&gt;Na tworzoną mapę typu Grid map nakładałem następnie wykryte obiekty. Do wyliczenia przesunięcia robota używałem wyłącznie enkoderów.&lt;/p&gt;
&lt;figure class=&quot;figure  figure--center&quot;&gt;
  &lt;img class=&quot;image&quot; src=&quot;/pics/RobotMapujacy/map.jpg&quot; alt=&quot;&quot; width=&quot;500&quot; height=&quot;800&quot; /&gt;
  
&lt;/figure&gt;

&lt;p&gt;&lt;a class=&quot;button&quot; href=&quot;https://github.com/TheDarkPhoenix/MappingRobotKinect&quot; style=&quot;background: #0366d6&quot;&gt;Mapowanie Kinect  &lt;svg width=&quot;16&quot; height=&quot;16&quot; class=&quot;icon  icon--github&quot; role=&quot;img&quot; alt=&quot;github&quot;&gt;&lt;title&gt;github&lt;/title&gt;&lt;use xlink:href=&quot;#github&quot; fill=&quot;CurrentColor&quot;&gt;&lt;/use&gt;&lt;/svg&gt;
&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;embed-container&quot;&gt;
  &lt;iframe width=&quot;720&quot; height=&quot;405&quot; src=&quot;https://drive.google.com/file/d/11cBjTDrB67s6sojRpdoVRc-anlgDSwj5/preview&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;
  &lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;&lt;a class=&quot;button&quot; href=&quot;https://github.com/TheDarkPhoenix/MappingRobotStereovision&quot; style=&quot;background: #0366d6&quot;&gt;Mapowanie Stereowizja  &lt;svg width=&quot;16&quot; height=&quot;16&quot; class=&quot;icon  icon--github&quot; role=&quot;img&quot; alt=&quot;github&quot;&gt;&lt;title&gt;github&lt;/title&gt;&lt;use xlink:href=&quot;#github&quot; fill=&quot;CurrentColor&quot;&gt;&lt;/use&gt;&lt;/svg&gt;
&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Próbowałem także wykorzystać SLAMa, aby zniwelować niedoskonałości enkoderów. Jednak tutaj barierą był system operacyjny - Windows, na którym nie udało mi się uruchomić żadnej implementacji. Było to także zbyt skomplikowane zadanie jak na wiedzę, którą posiadałem, aby stworzyć własną implementację.&lt;/p&gt;

&lt;figure class=&quot;figure  figure--center&quot;&gt;
  &lt;img class=&quot;image&quot; src=&quot;/pics/RobotMapujacy/pcb.jpg&quot; alt=&quot;&quot; width=&quot;600&quot; height=&quot;800&quot; /&gt;
  
&lt;/figure&gt;

&lt;p&gt;Do sterowania robotem użyłem mikrokontrolera Atmega88Pa. Komunikował się on z komputerem poprzez interfejs UART, wykorzystałem tutaj przejściówkę na USB. Sterował on silnikami - serwami pracy ciągłej. Także mierzył napięcie z transoptorów, zliczając impulsy poprzez zastowanie odpowiedniego progu. Także dla testu wykorzystałem podczerwony czujnik odległości. Do zasilenia całej konstrukcji użyłem akumulatora żelowego. Poprzez mikrokontroler mierzyłem jego napięcie, sprawdzając czy się rozładował. Musiałem także zastosować przetwornicę Step-Up, aby zasilić Kinecta, który wymaga 12V.&lt;/p&gt;

&lt;p&gt;&lt;a class=&quot;button&quot; href=&quot;https://github.com/TheDarkPhoenix/MappingRobotControler&quot; style=&quot;background: #0366d6&quot;&gt;Sterownik Robota  &lt;svg width=&quot;16&quot; height=&quot;16&quot; class=&quot;icon  icon--github&quot; role=&quot;img&quot; alt=&quot;github&quot;&gt;&lt;title&gt;github&lt;/title&gt;&lt;use xlink:href=&quot;#github&quot; fill=&quot;CurrentColor&quot;&gt;&lt;/use&gt;&lt;/svg&gt;
&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">Robot laptopa wożący pokój mapujący.</summary></entry><entry><title type="html">Efekt gitarowy Fuzz</title><link href="http://localhost:4000/elektronika/2015/06/20/fuzz/" rel="alternate" type="text/html" title="Efekt gitarowy Fuzz" /><published>2015-06-20T00:00:00+02:00</published><updated>2015-06-20T00:00:00+02:00</updated><id>http://localhost:4000/elektronika/2015/06/20/fuzz</id><content type="html" xml:base="http://localhost:4000/elektronika/2015/06/20/fuzz/">&lt;figure class=&quot;figure  figure--center&quot;&gt;
  &lt;img class=&quot;image&quot; src=&quot;/pics/fuzz/fuzz.jpg&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;300&quot; /&gt;
  
&lt;/figure&gt;

&lt;p&gt;Efekt gitarowy wykonany na podstawie schematu:&lt;/p&gt;
&lt;figure class=&quot;figure  figure--center&quot;&gt;
  &lt;img class=&quot;image&quot; src=&quot;/pics/fuzz/fuzzSchemat.gif&quot; alt=&quot;&quot; width=&quot;600&quot; height=&quot;800&quot; /&gt;
  
&lt;/figure&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">3D Viewer</title><link href="http://localhost:4000/oprogramowanie/2015/04/09/3dviewer/" rel="alternate" type="text/html" title="3D Viewer" /><published>2015-04-09T00:00:00+02:00</published><updated>2015-04-09T00:00:00+02:00</updated><id>http://localhost:4000/oprogramowanie/2015/04/09/3dviewer</id><content type="html" xml:base="http://localhost:4000/oprogramowanie/2015/04/09/3dviewer/">&lt;p&gt;Program służący do wyświetlania perspektywicznego punktów w 3D.&lt;/p&gt;

&lt;figure class=&quot;figure  figure--center&quot;&gt;
  &lt;img class=&quot;image&quot; src=&quot;/pics/3dviewer/viewer1.png&quot; alt=&quot;&quot; width=&quot;600&quot; height=&quot;800&quot; /&gt;
  
&lt;/figure&gt;

&lt;p&gt;Program ten napisałem w ramach lekcji Informatyki w Liceum. Zaimplementowałem wczytywanie chmur punktów z pliku txt. Są one w formacie współrzędne (X, Y, Z), a następnie kolory (R, G, B). Chmury punktów uzyskiwałem poprzez kamery stereowizyjne. Stworzyłem także możliwość wyświetlania kształtów geometrycznych, na przykład domku. Całość została napisana w Pascalu.&lt;/p&gt;

&lt;figure class=&quot;figure  figure--center&quot;&gt;
  &lt;img class=&quot;image&quot; src=&quot;/pics/3dviewer/viewer2.png&quot; alt=&quot;&quot; width=&quot;600&quot; height=&quot;800&quot; /&gt;
  
&lt;/figure&gt;

&lt;p&gt;&lt;a class=&quot;button&quot; href=&quot;https://github.com/TheDarkPhoenix/3DViewer&quot; style=&quot;background: #0366d6&quot;&gt;3DViewer  &lt;svg width=&quot;16&quot; height=&quot;16&quot; class=&quot;icon  icon--github&quot; role=&quot;img&quot; alt=&quot;github&quot;&gt;&lt;title&gt;github&lt;/title&gt;&lt;use xlink:href=&quot;#github&quot; fill=&quot;CurrentColor&quot;&gt;&lt;/use&gt;&lt;/svg&gt;
&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">Program służący do wyświetlania perspektywicznego punktów w 3D.</summary></entry><entry><title type="html">Robot uniwersalny</title><link href="http://localhost:4000/roboty/2014/08/28/universal-robots/" rel="alternate" type="text/html" title="Robot uniwersalny" /><published>2014-08-28T00:00:00+02:00</published><updated>2014-08-28T00:00:00+02:00</updated><id>http://localhost:4000/roboty/2014/08/28/universal-robots</id><content type="html" xml:base="http://localhost:4000/roboty/2014/08/28/universal-robots/">&lt;p&gt;Miał robić kawę…&lt;/p&gt;

&lt;p&gt;Tutaj wyobraźnia mnie poniosła i chciałem zrobić robota uniwersalnego zdolnego do wykonywania różnych czynności np. przygotować napoje, “chodzić” do sklepu. Oczywiście w zamyśle miała być to pierwsza wersja, na której chciałem zbadać moje możliwości. Podnosić miał jedynie atrapy, a poruszać się jedynie po domu.&lt;/p&gt;

&lt;figure class=&quot;figure  figure--center&quot;&gt;
  &lt;img class=&quot;image&quot; src=&quot;/pics/RobotUniwersalny/robot.jpg&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;800&quot; /&gt;
  
&lt;/figure&gt;

&lt;p&gt;Piękna była to konstrukcja i bardzo skomplikowana. Do obsługi wszystkich kończyn planowałem zastosować 11 serw. Znacznie przekroczyło to liczbę kanałów PWM w mikrokontrolerze Atmega88Pa. Dlatego właśnie zmuszony byłem zastosować programowe generowanie PWM, które znacznie bardziej obciąża procesor. Z tego właśnie powodu zmuszony byłem użyć drugi mikrokontroler odpowiedzialny za komunikację z komputerem, sterowaniem silnikami oraz zadawanie poprzez SPI położeń serw do drugiego mikrokontrolera. Wiele rzeczy mogło się zepsuć po drodze, dlatego gdy ostatecznie nie mogłem zapanować nad serwami nie wiedziałem co się dzieje. Dopiero po dłuższym czasie doszedłem do wniosku, że musiałem mieć za słabe źródło zasilania, coś czego wcześniej nawet nie brałem pod uwagę. Jednak pomimo niedziałających serw nie porzuciłem tej konstrukcji. Wciąż miałem działające silniki, którymi mogłem sterować z poziomu komputera. Zająłem się w takim razie niezbędnym elementem takiego robota - wykrywaniem przeszkód oraz mapowaniem. W tym celu chciałem zasotosować parę stereowizyjną. Po wielu przygodach udało mi się wreszcie doprowadzić stereowizję do poziomu zadowalającego. Wciąż jednak występowało dużo szumów - szczególnie na podłodze. Nic dziwnego, podłoga, ściana, to mało szczegółów i ciężko jest uzyskać pewny obraz głębi. Udało się zatem mniej więcej wykrywać przeszkody, jednak gdy doszedł do tego ruch to już kompletnie co innego. Zastosowane kamerki internetowe zwracały poruszone obrazy co jeszcze pogarszało wynik wykrywania. Do tego nie zastosowałem enkoderów, ponieważ planowałem wykrywać punkty szczególne i póżniej na podstawie ich oraz uzyskanej mapy głębokości obliczać przesunięcie. Po takich jednak rozczarowujących efektach stereowizji nie próbowałem już tego rozwiązania.&lt;/p&gt;

&lt;figure class=&quot;figure  figure--center&quot;&gt;
  &lt;img class=&quot;image&quot; src=&quot;/pics/RobotUniwersalny/parts.jpg&quot; alt=&quot;&quot; width=&quot;600&quot; height=&quot;800&quot; /&gt;
  
&lt;/figure&gt;

&lt;p&gt;Pomimo, że nie spełnił moich oczekiwań to wyszła z niego ciekawa konstrukcja. I mój początek przygody ze stereowizją i mapowaniem.&lt;/p&gt;

&lt;p&gt;W tej konstrukcji wzorowałem się na robocie PR2. Domyślną wersję tej konstrukcji chciałem wykonać 2 razy większą. Zastosowanie tutaj zgięcia w połowie miało na celu zwiększyć zakres chwytania - możliwość schylenia się. Jednak głównym celem była możliwość przetransformowania się w robota jeżdżącego, co umowżliwiłoby wspinanie się po schodach oraz większych przeszkodach. Domyślnie w napędzie chciałem zastosować gąsienice.&lt;/p&gt;</content><author><name></name></author><summary type="html">Miał robić kawę...</summary></entry><entry><title type="html">Elektroniczna kostka</title><link href="http://localhost:4000/elektronika/2014/03/22/elektronicznakostka/" rel="alternate" type="text/html" title="Elektroniczna kostka" /><published>2014-03-22T00:00:00+01:00</published><updated>2014-03-22T00:00:00+01:00</updated><id>http://localhost:4000/elektronika/2014/03/22/elektronicznakostka</id><content type="html" xml:base="http://localhost:4000/elektronika/2014/03/22/elektronicznakostka/">&lt;p&gt;Projekt elektronicznej kostki wykonany na podstawie przykładu w książce “Elektronika. Od praktyki do teorii”&lt;/p&gt;

&lt;figure class=&quot;figure  figure--center&quot;&gt;
  &lt;img class=&quot;image&quot; src=&quot;/pics/elektronicznaKostka/szostka.jpg&quot; alt=&quot;&quot; width=&quot;600&quot; height=&quot;800&quot; /&gt;
  
&lt;/figure&gt;

&lt;p&gt;W układzie wykorzystany jest układ czasowy 555 do generacji impulsów, które następnie zliczane są w szóstkach. Odpowiednie liczby są wyświetlane na diodach. Proces zatrzymywany jest przez wciśnięcie przycisku co powoduje zatrzymanie się na “losowej” wartości. Impulsy są generowany na tyle szybko, że nie da sie wychwycić jaka aktualnie cyfra jest wyświetlana.&lt;/p&gt;

&lt;p&gt;Proces wykonania:&lt;/p&gt;

&lt;figure class=&quot;figure  figure--center&quot;&gt;
  &lt;img class=&quot;image&quot; src=&quot;/pics/elektronicznaKostka/prototyp.jpg&quot; alt=&quot;Prototyp na płytce stykowej&quot; width=&quot;600&quot; height=&quot;800&quot; /&gt;
  &lt;figcaption class=&quot;caption&quot;&gt;Prototyp na płytce stykowej&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure class=&quot;figure  figure--center&quot;&gt;
  &lt;img class=&quot;image&quot; src=&quot;/pics/elektronicznaKostka/elementy.jpg&quot; alt=&quot;Płytka uniwersalna wraz z użytymi elementami&quot; width=&quot;600&quot; height=&quot;800&quot; /&gt;
  &lt;figcaption class=&quot;caption&quot;&gt;Płytka uniwersalna wraz z użytymi elementami&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure class=&quot;figure  figure--center&quot;&gt;
  &lt;img class=&quot;image&quot; src=&quot;/pics/elektronicznaKostka/trojka.jpg&quot; alt=&quot;Zmontowana kostka&quot; width=&quot;600&quot; height=&quot;800&quot; /&gt;
  &lt;figcaption class=&quot;caption&quot;&gt;Zmontowana kostka&lt;/figcaption&gt;
&lt;/figure&gt;</content><author><name></name></author><summary type="html">Projekt elektronicznej kostki wykonany na podstawie przykładu w książce &quot;Elektronika. Od praktyki do teorii&quot;</summary></entry><entry><title type="html">2D Racing</title><link href="http://localhost:4000/oprogramowanie/2014/01/18/2dracing/" rel="alternate" type="text/html" title="2D Racing" /><published>2014-01-18T00:00:00+01:00</published><updated>2014-01-18T00:00:00+01:00</updated><id>http://localhost:4000/oprogramowanie/2014/01/18/2dracing</id><content type="html" xml:base="http://localhost:4000/oprogramowanie/2014/01/18/2dracing/">&lt;p&gt;Gra wyścigowa 2D z widokiem od góry. Napisana w języku C++ przy pomocy bibliotek SFML oraz Box2D.&lt;/p&gt;

&lt;figure class=&quot;figure  figure--center&quot;&gt;
  &lt;img class=&quot;image&quot; src=&quot;/pics/2dracing/2dracing1.png&quot; alt=&quot;&quot; width=&quot;500&quot; height=&quot;800&quot; /&gt;
  
&lt;/figure&gt;

&lt;p&gt;Gra ta została wykonana także w ramach projektu z Informatyki. Umożliwia ściganie się z przeciwnikami na różnych torach. Możemy także tworzyć własne trasy w osobnym edytorze, który także napisałem w ramach projektu. Tor podzielony jest na kwadraty o określonym typie: prosta, zekręt w lewo, prawo, trawa oraz meta.&lt;/p&gt;
&lt;div class=&quot;embed-container&quot;&gt;
  &lt;iframe width=&quot;720&quot; height=&quot;405&quot; src=&quot;https://drive.google.com/file/d/1caP0KGbfBlv4BPnuFSBJOfECxKKN5w26/preview&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;
  &lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;&lt;a class=&quot;button&quot; href=&quot;https://github.com/TheDarkPhoenix/2DRacing-Map-Editor&quot; style=&quot;background: #0366d6&quot;&gt;Edytor map  &lt;svg width=&quot;16&quot; height=&quot;16&quot; class=&quot;icon  icon--github&quot; role=&quot;img&quot; alt=&quot;github&quot;&gt;&lt;title&gt;github&lt;/title&gt;&lt;use xlink:href=&quot;#github&quot; fill=&quot;CurrentColor&quot;&gt;&lt;/use&gt;&lt;/svg&gt;
&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Dzięki zawarciu w pliku tekstowym informacji o odpowiednich kwadratach oraz odczycie aktualnej pozycji samochodu wprowadziłem pewną formę sztucznej inteligencji, z którą możemy się wyścigować. Przeciwnicy reagują na znalezienie się na fragmencie toru odpowiednio skręcaniem, przyspieszaniem lub hamowaniem. Cała symulacja jazdy oraz zderzeń oparta jest na bibliotece Box2D. Dzięki temu udało mi się uzyskać realistyczne interakcje między samochodami.&lt;/p&gt;
&lt;div class=&quot;embed-container&quot;&gt;
  &lt;iframe width=&quot;720&quot; height=&quot;405&quot; src=&quot;https://drive.google.com/file/d/1R87yQX23XnZ25PLVj8EW65OP0qda675Z/preview&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;
  &lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;&lt;a class=&quot;button&quot; href=&quot;https://github.com/TheDarkPhoenix/2DRacing&quot; style=&quot;background: #0366d6&quot;&gt;2DRacing  &lt;svg width=&quot;16&quot; height=&quot;16&quot; class=&quot;icon  icon--github&quot; role=&quot;img&quot; alt=&quot;github&quot;&gt;&lt;title&gt;github&lt;/title&gt;&lt;use xlink:href=&quot;#github&quot; fill=&quot;CurrentColor&quot;&gt;&lt;/use&gt;&lt;/svg&gt;
&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">Gra wyścigowa 2D z widokiem od góry. Napisana w języku C++ przy pomocy bibliotek SFML oraz Box2D.</summary></entry></feed>